# Reflection

Student Name:  name
Sudent Email:  email

## Instructions

Reflection is a key activity of learning. It helps you build a strong metacognition, or "understanding of your own learning." A good learner not only "knows what they know", but they "know what they don't know", too. Learning to reflect takes practice, but if your goal is to become a self-directed learner where you can teach yourself things, reflection is imperative.

- Now that you've completed the assignment, share your throughts. What did you learn? What confuses you? Where did you struggle? Where might you need more practice?
- A good reflection is: **specific as possible**,  **uses the terminology of the problem domain** (what was learned in class / through readings), and **is actionable** (you can pursue next steps, or be aided in the pursuit). That last part is what will make you a self-directed learner.
- Flex your recall muscles. You might have to review class notes / assigned readings to write your reflection and get the terminology correct.
- Your reflection is for **you**. Yes I make you write them and I read them, but you are merely practicing to become a better self-directed learner. If you read your reflection 1 week later, does what you wrote advance your learning?

Examples:

- **Poor Reflection:**  "I don't understand loops."   
**Better Reflection:** "I don't undersand how the while loop exits."   
**Best Reflection:** "I struggle writing the proper exit conditions on a while loop." It's actionable: You can practice this, google it, ask Chat GPT to explain it, etc. 
-  **Poor Reflection** "I learned loops."   
**Better Reflection** "I learned how to write while loops and their difference from for loops."   
**Best Reflection** "I learned when to use while vs for loops. While loops are for sentiel-controlled values (waiting for a condition to occur), vs for loops are for iterating over collections of fixed values."

`--- Reflection Below This Line ---`
So far in the project, I’ve been working on building a data pipeline using the Google Places API and Azure Sentiment Analysis to process review data. This involved learning how to interact with external APIs, handle JSON responses, and normalize complex nested data into a format suitable for analysis. I’ve also practiced working with pandas to manipulate and clean the data at various stages, including extracting specific fields, renaming columns, and filtering for the necessary information. While processing the reviews, I encountered an issue where the required place_ids.csv file was missing, preventing the pipeline from proceeding. Although I initially planned to extract the Place IDs directly from the API, I haven't been able to implement this solution fully yet. The main challenge right now is resolving the issue with the missing file, which is necessary to continue making API calls. Once this is sorted, the goal is to complete the sentiment analysis and entity extraction steps, ensuring the pipeline works end-to-end.
